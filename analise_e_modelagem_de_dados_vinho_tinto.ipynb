{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignorar os avisos\n",
    "import warnings\n",
    "warnings.filterwarnings('always')  # Configurar para mostrar todos os avisos\n",
    "warnings.filterwarnings('ignore')  # Ignorar os avisos\n",
    "\n",
    "# Visualização e manipulação de dados\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.datasets import fetch_openml  # Adicionada\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "# Configuração\n",
    "style.use('fivethirtyeight')  # Estilo de plotagem\n",
    "sns.set(style='whitegrid', color_codes=True)  # Configurações de estilo para Seaborn\n",
    "\n",
    "# Importar algoritmos de modelagem necessários.\n",
    "\n",
    "# Classificação.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Regressão\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Seleção de modelo\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Pré-processamento\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer  # Importar o SimpleImputer do módulo sklearn.impute\n",
    "\n",
    "# Métricas de avaliação\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error, r2_score, mean_absolute_error  # para regressão\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score  # para classificação\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('analise_vinho_tinto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de Correlação das Características da Qualidade do Vinho\n",
    "\n",
    "Através da aplicação das técnicas de correlação de Pearson e Spearman, podemos discernir as características que mais influenciam a qualidade do vinho. Os resultados indicam que as variáveis de álcool e densidade apresentam as maiores correlações. A análise de Spearman ainda revela o cloreto como uma variável com significativa correlação, enquanto a análise de Pearson destaca a acidez volátil. É fundamental notar, no entanto, que nenhuma dessas correlações ultrapassa o limiar de 0,5, sugerindo uma relação moderada entre as características e a qualidade do vinho.\n",
    "\n",
    "Explorando as características de menor correlação, observamos que, em ambos os conjuntos de dados, o açúcar residual exibe a menor correlação. Além disso, na análise de Spearman, os sulfatos demonstram uma correlação fraca, enquanto na análise de Pearson, o pH é a variável com a correlação mais baixa.\n",
    "\n",
    "Essas descobertas fornecem insights valiosos sobre os fatores que afetam a qualidade do vinho, informando futuras investigações e aprimorando nossa compreensão das relações entre as características químicas e organolépticas dessa bebida apreciada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(method = \"spearman\", numeric_only = True)['qualidade'].sort_values().plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(method = \"pearson\", numeric_only = True)['qualidade'].sort_values().plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data = df,\n",
    "           x = \"qualidade\",\n",
    "           y = \"alcool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise univariada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de Relação entre Notas e Teor Alcoólico de Vinhos\n",
    "\n",
    "Nesta análise, investigamos a relação entre a pontuação de vinhos e seu teor alcoólico. Os resultados revelam uma tendência notável: vinhos com classificação superior (9) tendem a apresentar teores alcoólicos mais elevados. No entanto, é crucial observar que a presença de um alto teor alcoólico não é, por si só, um indicativo infalível de qualidade, visto que identificamos casos atípicos de vinhos com uma pontuação de 5 que exibem elevado teor alcoólico.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data = df,\n",
    "           x = \"alcool\",\n",
    "           hue = \"qualidade\",\n",
    "           common_norm = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise das Relações entre Classificação de Vinhos e Teor Alcoólico\n",
    "\n",
    "Neste estudo, exploramos as relações entre a classificação de vinhos e seu teor alcoólico com base em dados empíricos. O gráfico apresentado acima ilustra as conclusões extraídas dessa análise.\n",
    "\n",
    "## Resultados da Análise\n",
    "\n",
    "O gráfico confirma de forma convincente a existência de uma correlação entre a classificação dos vinhos e seu teor alcoólico. Em particular, destacamos as seguintes descobertas:\n",
    "\n",
    "- Vinhos com classificações mais elevadas, variando entre 7 e 9, exibem um teor alcoólico superior. Isso é evidenciado pela presença de um pico notável na densidade de amostras de vinho, concentrado entre 11 e 13 graus de álcool.\n",
    "\n",
    "- Por outro lado, os vinhos com classificações mais baixas apresentam uma densidade de amostras mais significativa em uma faixa de graduação alcoólica entre 9 e 10.\n",
    "\n",
    "Esses resultados sugerem que o teor alcoólico pode ser um fator relevante na classificação de vinhos, com vinhos mais alcoólicos geralmente recebendo classificações mais altas. Essa associação entre classificação e teor alcoólico pode ser de interesse para produtores, apreciadores e entusiastas de vinho que desejam compreender melhor os fatores subjacentes à apreciação de vinhos.\n",
    "\n",
    "É importante notar que essa análise se baseia em dados disponíveis e pode não capturar todas as nuances do mundo dos vinhos. No entanto, os resultados aqui apresentados oferecem uma visão valiosa das relações entre classificação de vinhos e teor alcoólico, proporcionando um ponto de partida para investigações mais aprofundadas e tomada de decisões informadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Os historiogramas são úteis para entender a distribuição de dados, identificar tendências, padrões e outliers em um conjunto de dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 5)\n",
    "colunas = ['acidez_fixa', 'acidez_volatil', 'acido_citrico', 'acucar_residual',\n",
    "           'cloreto', 'dioxido_enxofre_livre', 'dioxido_enxofre_total',\n",
    "           'densidade', 'pH', 'sulfatos', 'alcool', 'qualidade']\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        axes[i, j].hist(x=colunas[i + j], data=df,\n",
    "                        edgecolor='#000000', linewidth=2, color='#ff4125')\n",
    "        axes[i, j].set_title('Variação de ' + colunas[i + j])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18, 18)\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlação entre diferentes características usando um mapa de correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_correlacao = df.corr()\n",
    "mascara = np.array(matriz_correlacao)\n",
    "mascara[np.tril_indices_from(mascara)] = False\n",
    "figura = plt.gcf()\n",
    "figura.set_size_inches(30, 12)\n",
    "\n",
    "# Usar a paleta de cores \"Reds\" para criar um degradê de tons de vermelho\n",
    "sns.heatmap(data=matriz_correlacao, mask=mascara, square=True, annot=True, cbar=True, cmap=\"Reds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INFERÊNCIAS DO MAPA DE CALOR ACIMA:**\n",
    "\n",
    "1. A qualidade do vinho está altamente relacionada à acidez volátil.\n",
    "\n",
    "2. Além disso, a qualidade do vinho está altamente correlacionada com o teor alcoólico.\n",
    "\n",
    "3. O pH e o ácido cítrico/ acidez fixa estão altamente inversamente relacionados, pois todos sabemos que os ácidos têm valores de pH menores.\n",
    "\n",
    "4. A relação consigo mesma (ou seja, de uma característica consigo mesma) é igual a 1, como esperado.\n",
    "\n",
    "5. Outras inferências semelhantes podem ser feitas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agora é possível visualizar a variação da qualidade em relação a distintos atributos numéricos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A função cria e exibe três gráficos em uma única chamada, usando os parâmetros fornecidos. É útil quando desejar visualizar diferentes aspectos da relação entre duas variáveis em um conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(feature_x, target='qualidade'):\n",
    "    sns.catplot(x=target, y=feature_x, data=df, kind='bar', height=5, aspect=1)\n",
    "    sns.catplot(x=target, y=feature_x, data=df, kind='violin', height=5, aspect=1)\n",
    "    sns.catplot(x=target, y=feature_x, data=df, kind='swarm', height=5, aspect=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot('alcool','qualidade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação Concluída: Avançando para a Modelagem de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervalos = (2, 6.5, 8)\n",
    "nomes_grupos = ['ruim', 'bom']\n",
    "df['qualidade'] = pd.cut(df['qualidade'], bins=intervalos, labels=nomes_grupos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma instância do LabelEncoder\n",
    "codificador_rotulos = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Uma explicação sucinta sobre o LabelEncoder: Esta classe, parte da biblioteca scikit-learn (sklearn), é amplamente empregada para converter rótulos (categorias) em variáveis categóricas em valores numéricos. Essa conversão é essencial ao treinar modelos de aprendizado de máquina que exigem entradas numéricas em vez de categóricas. Por exemplo, permite transformar rótulos de classes, como \"ruim\" e \"bom\", em valores 0 e 1, tornando-os adequados como entradas para modelos de machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Ruim\" se torna 0 e \"Bom\" se torna 1\n",
    "df['qualidade'] = codificador_rotulos.fit_transform(df['qualidade'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Divisão de Dados para Treinamento e Teste:**\n",
    "\n",
    "Este código divide um conjunto de dados em duas partes: uma para treinar um modelo de machine learning (conjunto de treinamento) e outra para testar o modelo (conjunto de teste). Ele separa as características do conjunto de destino (rótulos) e permite avaliar o desempenho do modelo ao usar dados que não foram usados no treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino, x_teste, y_treino, y_teste = train_test_split(\n",
    "    df.drop('qualidade', axis=1), df['qualidade'], test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação de Modelos de Classificação e Cálculo da Acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de modelos de classificação\n",
    "modelos = [LinearSVC(), SVC(kernel='rbf'), KNeighborsClassifier(), RandomForestClassifier(),\n",
    "           DecisionTreeClassifier(), GradientBoostingClassifier()]\n",
    "\n",
    "\n",
    "nomes_dos_modelos = ['LinearSVM','rbfSVM','KNearestNeighbors','RandomForestClassifier','DecisionTree',\n",
    "             'GradientBoostingClassifier',]\n",
    "\n",
    "acuracias = []  # Lista para armazenar as acurácias dos modelos\n",
    "resultados = {}  # Dicionário para armazenar os resultados\n",
    "\n",
    "for i, modelo in enumerate(modelos):\n",
    "    clf = modelo  # clf é uma abreviação comum para \"classificador\"\n",
    "    clf.fit(x_treino, y_treino)  # Treina o classificador com os dados de treinamento\n",
    "    previsoes = clf.predict(x_teste)  # Faz previsões com o conjunto de teste\n",
    "    acuracia = accuracy_score(previsoes, y_teste)  # Calcula a acurácia das previsões\n",
    "    acuracias.append(acuracia)  # Adiciona a acurácia à lista de acurácias\n",
    "\n",
    "# Preenche o dicionário de resultados com os nomes dos modelos e suas acurácias correspondentes\n",
    "resultados['Algoritmo de Modelagem'] = nomes_dos_modelos\n",
    "resultados['Acurácia'] = acuracias\n",
    "\n",
    "resultados  # Retorna o dicionário de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracias_frame = pd.DataFrame(resultados)\n",
    "acuracias_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y='Algoritmo de Modelagem',x='Acurácia',data=acuracias_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Algoritmo de Modelagem',y='Acurácia',data=acuracias_frame, kind='point', height=4, aspect=3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No contexto da análise de dados, é importante notar que, inicialmente, as características não foram submetidas a nenhum tipo de escala. Isso significa que essas características têm diferentes escalas, o que implica que seus valores estão em intervalos ou unidades distintas. Agora, com o objetivo de entender melhor o impacto disso, a próxima etapa é realizar a escala das características. O escalonamento de características é uma prática comum em ciência de dados, utilizada para padronizar as características em uma escala uniforme. Essa ação visa avaliar como essa padronização afeta os resultados e o desempenho do modelo ou da análise em questão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliar_modelos(x_treino, x_teste, y_treino, y_teste, nome_escalonador):\n",
    "    # Lista de modelos a serem avaliados\n",
    "# Lista de modelos de classificação\n",
    "    modelos = [LinearSVC(), SVC(kernel='rbf'), KNeighborsClassifier(), RandomForestClassifier(),\n",
    "           DecisionTreeClassifier(), GradientBoostingClassifier()]\n",
    "           \n",
    "    resultados_acuracia = []\n",
    "\n",
    "    # Avaliar cada modelo\n",
    "    for modelo in modelos:\n",
    "        clf = modelo\n",
    "        clf.fit(x_treino, y_treino)\n",
    "        previsoes = clf.predict(x_teste)\n",
    "        resultados_acuracia.append(accuracy_score(previsoes, y_teste))\n",
    "\n",
    "    # Armazenar os resultados no dataframe\n",
    "    acuracias_frame[nome_escalonador] = np.array(resultados_acuracia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair o array de labels 'qualidade' do DataFrame\n",
    "Y = df['qualidade'].to_numpy()\n",
    "\n",
    "# Lista de escaladores a serem aplicados aos dados\n",
    "escaladores = [MinMaxScaler(), StandardScaler()]\n",
    "\n",
    "# Nomes descritivos para os resultados dos escaladores\n",
    "nomes_escalonadores = ['Acuracia_Min_Max_Scaler', 'Acuracia_Standard_Scaler']\n",
    "\n",
    "# Iterar através dos escaladores e avaliar os modelos\n",
    "for escala in range(len(escaladores)):\n",
    "    escalador = escaladores[escala]\n",
    "\n",
    "    # Aplicar o escalador aos dados\n",
    "    escalador.fit(df)\n",
    "    df_escalado = escalador.transform(df)\n",
    "\n",
    "    # Selecionar as características escaladas \n",
    "    X = df_escalado[:,0:6]\n",
    "\n",
    "    # Reatribuir Y com os rótulos de 'qualidade'\n",
    "    Y = df['qualidade'].to_numpy()\n",
    "\n",
    "    # Dividir os dados em treino e teste\n",
    "    x_treino, x_teste, y_treino, y_teste = train_test_split(\n",
    "        X, Y, test_size=0.25, random_state=42)\n",
    "\n",
    "    # Avaliar os modelos com o nome do escalador correspondente\n",
    "    avaliar_modelos(x_treino, x_teste, y_treino,\n",
    "                    y_teste, nomes_escalonadores[escala])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Técnicas de Escalonamento no Desempenho de Modelos de Classificação\n",
    "\n",
    "O código tem o objetivo de avaliar como diferentes técnicas de escalonamento afetam o desempenho de modelos de classificação em um conjunto de dados específico. Utilizando a função `avaliar_modelos`, o código examina vários modelos de classificação em dados de treinamento e teste, fornecendo resultados que permitem a comparação do desempenho desses modelos após a aplicação de técnicas de escalonamento, como Min-Max Scaling e Standard Scaling. Esse processo é fundamental para determinar qual abordagem de pré-processamento de dados é mais eficaz na otimização do desempenho dos modelos, desempenhando um papel crucial no desenvolvimento de soluções de machine learning de sucesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracias_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste momento, apresenta-se de forma clara as precisões de diferentes algoritmos de modelagem ao utilizar diferentes escaladores.\n",
    "\n",
    "1. É importante notar que, neste contexto, as precisões aumentam marginalmente ao realizar o escalonamento.\n",
    "\n",
    "2. Adicionalmente, para esses dados, o StandardScaling parece proporcionar resultados ligeiramente superiores em comparação com o MinMaxScaling.\n",
    "\n",
    "3. Para alguns algoritmos de modelagem, observa-se um aumento significativo nas precisões ao escalonar as características, como SVM e KNN, enquanto, para outros, não se observa um aumento considerável nas precisões ao realizar o escalonamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# código cria um gráfico de barras que ajuda a comparar a precisão de vários algoritmos de modelagem\n",
    "\n",
    "sns.barplot(y='Algoritmo de Modelagem',x='Acurácia',data=acuracias_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y='Algoritmo de Modelagem',x='Acuracia_Min_Max_Scaler',data=acuracias_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y='Algoritmo de Modelagem',x='Acuracia_Standard_Scaler',data=acuracias_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrai a coluna 'qualidade' como o alvo (variável de saída) Y e converte-a em um array NumPy.\n",
    "Y = df['qualidade'].to_numpy()\n",
    "\n",
    "# Prepara as features (variáveis de entrada) utilizando um StandardScaler para padronização dos dados, uma vez que isso produziu resultados melhores no passado.\n",
    "escalador = StandardScaler()\n",
    "df_escalado = escalador.fit_transform(df)\n",
    "X = df_escalado[:, 0:11]  # Seleciona as colunas de 0 a 10 como as features padronizadas.\n",
    "\n",
    "# Reatribui Y para garantir que estamos usando a variável alvo correta.\n",
    "Y = df['qualidade'].to_numpy()\n",
    "\n",
    "# Divide os dados em conjuntos de treinamento e teste usando a função train_test_split.\n",
    "# 75% dos dados serão usados para treinamento (x_treino, y_treino) e 25% para teste (x_teste, y_teste).\n",
    "# O valor de random_state é definido como 42 para garantir a reprodutibilidade dos resultados.\n",
    "x_treino, x_teste, y_treino, y_teste, = train_test_split(X, Y, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.   LOGISTIC REGRESSION."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo uma lista de valores para os hiperparâmetros C e penalty\n",
    "parametros_lr = {'C': [0.001, 0.01, 0.1, 1,\n",
    "                    10, 100, 1000], 'penalty': ['l1', 'l2']}\n",
    "\n",
    "# Criando um estimador de Regressão Logística para otimização de hiperparâmetros\n",
    "classificador_lr = GridSearchCV(estimator=LogisticRegression(),\n",
    "                      param_grid=parametros_lr, scoring='accuracy', cv=10)\n",
    "\n",
    "# Ajustando (treinando) o modelo com os dados de treinamento x_treino e y_treino\n",
    "classificador_lr.fit(x_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém os melhores hiperparâmetros encontrados durante a otimização.\n",
    "classificador_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtém a melhor pontuação (geralmente acurácia) alcançada com os melhores hiperparâmetros.\n",
    "classificador_lr.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessa os resultados completos da validação cruzada, incluindo as métricas para cada combinação de hiperparâmetros.\n",
    "classificador_lr.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz previsões com o modelo otimizado nos dados de teste.\n",
    "previsoes = classificador_lr.predict(x_teste)\n",
    "\n",
    "# Calcula a acurácia das previsões comparando com os valores reais nos dados de teste.\n",
    "accuracy_score(previsoes, y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######   2. KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma lista de valores para o número de vizinhos\n",
    "lista_vizinhos = [i + 1 for i in range(50)]\n",
    "\n",
    "# Define um dicionário de parâmetros para o KNeighborsClassifier\n",
    "parametros_knn = {'n_neighbors': lista_vizinhos, 'n_jobs': [-1]}\n",
    "\n",
    "# Cria um classificador KNeighborsClassifier com busca em grade\n",
    "classificador_knn = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=parametros_knn, scoring='accuracy', cv=10)\n",
    "\n",
    "# Treina o classificador com os dados de treinamento\n",
    "classificador_knn.fit(x_treino,y_treino)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador_knn.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador_knn.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz previsões com o modelo otimizado nos dados de teste.\n",
    "previsoes = classificador_knn.predict(x_teste)\n",
    "\n",
    "# Calcula a acurácia das previsões comparando com os valores reais nos dados de teste.\n",
    "accuracy_score(previsoes, y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######   3. RANDOM FOREST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição dos parâmetros para o Random Forest\n",
    "parametros_rf = {'n_estimators': [500],  # Número de árvores na floresta\n",
    "                 'max_features': ['auto', 'sqrt', 'log2']}  # Método de seleção de características\n",
    "\n",
    "# Criação do classificador Random Forest com Grid Search Cross-Validation\n",
    "classificador_rf = GridSearchCV(estimator=RandomForestClassifier(n_jobs=-1),\n",
    "                                param_grid=parametros_rf,  # Parâmetros a serem ajustados\n",
    "                                scoring='accuracy',  # Métrica de avaliação\n",
    "                                cv=10)  # Validação cruzada com 10 folds\n",
    "\n",
    "# Treinamento do classificador Random Forest\n",
    "classificador_rf.fit(x_treino, y_treino)  # Dados de treinamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador_rf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = classificador_rf.predict(x_teste)\n",
    "accuracy_score(previsoes,y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4. GRADIENT BOOSTING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializando o classificador Gradient Boosting com GridSearchCV.\n",
    "classificador_gb = GridSearchCV(estimator=GradientBoostingClassifier(\n",
    "), cv=10, param_grid={'n_estimators': [500]})\n",
    "\n",
    "# Treinando o classificador Gradient Boosting com os dados de treinamento.\n",
    "classificador_gb.fit(x_treino, y_treino)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador_gb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador_gb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador_gb.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = classificador_gb.predict(x_teste)\n",
    "accuracy_score(previsoes,y_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apoś o ajuste de parâmetros , o SVM com o kernel RBF alcançou a mais alta precisão, que foi de 91,75%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
